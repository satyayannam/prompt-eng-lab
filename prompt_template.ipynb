{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template Prompting\n",
    "\n",
    "Prompt Template Prompting refers to a technique where predefined templates are used to construct effective prompts that guide large language models (LLMs) to generate responses tailored to specific use cases. The templates typically contain static text combined with dynamic input variables, allowing for consistent, reusable, and customizable prompts.\n",
    "\n",
    "Prompt templates are widely used across various domains, such as:\n",
    "* **Question Generation**: Templates can generate quiz questions by filling in variables related to topics.\n",
    "* **Text Summarization**: Static instructions combined with variable documents or inputs allow flexible summarization.\n",
    "* **Coding Assistance**: Dynamic prompts help LLMs generate code snippets for different programming tasks.\n",
    "\n",
    "## References:\n",
    "\n",
    "* (OpenAI Documentation for Prompt Engineering)[https://platform.openai.com/docs/guides/prompt-engineering]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fprompt_template.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': 'You are an AI tutor explaining complex topics in a simple way.\\nExplain the concept of Decision Trees and their advantages.\\nProvide a structured response using numbered steps.', 'stream': False, 'options': {'temperature': 0.7, 'num_ctx': 200, 'num_predict': 200}}\n",
      "I'd be happy to explain Decision Trees in a simple way.\n",
      "\n",
      "**What is a Decision Tree?**\n",
      "\n",
      "A Decision Tree is a visual representation of decisions and their possible outcomes. It's like a flowchart that helps you make decisions by considering different options and their consequences.\n",
      "\n",
      "**Here are the steps to understand Decision Trees:**\n",
      "\n",
      "1. **Start with a Problem**: Identify a problem or decision you want to solve, such as predicting whether someone will buy a product based on their age, income, and location.\n",
      "2. **Create a Root Node**: This is the starting point of your tree. It represents the initial condition or feature that you're considering (e.g., \"Is the customer old enough to be interested in our product?\").\n",
      "3. **Split into Branches**: Based on the root node, create two or more branches that represent different options or conditions. For example:\n",
      "\t* \"Older than 30\" -> yes or no\n",
      "\t* \"Income above $50,000\n",
      "Time taken: 94.21s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## PROMPT TEMPLATE PROMPTING\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "MESSAGE = \"Explain the concept of Decision Trees and their advantages.\"\n",
    "\n",
    "TEMPLATE_BEFORE = \"You are an AI tutor explaining complex topics in a simple way.\"\n",
    "TEMPLATE_AFTER = \"Provide a structured response using numbered steps.\"\n",
    "\n",
    "PROMPT = TEMPLATE_BEFORE + '\\n' + MESSAGE + '\\n' + TEMPLATE_AFTER  \n",
    "\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=0.7, \n",
    "                         num_ctx=200, \n",
    "                         num_predict=200)\n",
    "\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
