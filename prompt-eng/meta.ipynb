{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Prompting\n",
    "\n",
    "Meta prompting is an advanced technique in prompt engineering that emphasizes the structural and syntactical organization of tasks and problems rather than focusing on their specific content. The objective is to create a more abstract, form-driven way of engaging with large language models (LLMs), highlighting patterns and structure over traditional content-focused methods.\n",
    "\n",
    "As outlined by [Zhang et al. (2024)](https://arxiv.org/abs/2311.11482), the defining features of meta prompting include:\n",
    "\n",
    "* Structure-Oriented: Prioritizes the organization and pattern of problems and solutions instead of specific content.\n",
    "* Syntax-Guided: Leverages syntax as a template to shape the expected responses or solutions.\n",
    "* Abstract Frameworks: Uses abstract examples as blueprints, demonstrating the structure of tasks without relying on concrete details.\n",
    "* Domain Versatility: Can be applied across multiple fields, offering structured solutions to diverse problem types.\n",
    "* Categorical Approach: Draws on type theory to organize and categorize components logically, enhancing prompt coherence and precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fmeta.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': '\\nGenerate a highly structured and effective prompt to help students learn about Explain the concept of Decision Trees and their advantages..\\nEnsure the generated prompt guides them step by step and requests detailed explanations with examples.\\n', 'stream': False, 'options': {'temperature': 0.7, 'num_ctx': 150, 'num_predict': 150}}\n",
      "Here's a structured prompt to guide students in learning about decision trees and their advantages:\n",
      "\n",
      "**Prompt:**\n",
      "\n",
      "**Assignment:** Explain the Concept of Decision Trees and Their Advantages\n",
      "\n",
      "**Objective:** To understand the basics of decision trees, how they work, and their advantages over other machine learning algorithms.\n",
      "\n",
      "**Step 1: Introduction (10 points)**\n",
      "\n",
      "* Define what a decision tree is in simple terms.\n",
      "* Provide examples of real-world scenarios where decision trees are commonly used (e.g., credit risk assessment, medical diagnosis).\n",
      "* Discuss the benefits of using decision trees compared to other machine learning techniques.\n",
      "\n",
      "**Step 2: How Decision Trees Work (20 points)**\n",
      "\n",
      "* Explain the basic components of a decision tree:\n",
      "\t+ Root node\n",
      "\t\n",
      "Time taken: 67.004s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## META PROMPTING\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "MESSAGE = \"Explain the concept of Decision Trees and their advantages.\"\n",
    "\n",
    "META_PROMPT = f\"\"\"\n",
    "Generate a highly structured and effective prompt to help students learn about {MESSAGE}.\n",
    "Ensure the generated prompt guides them step by step and requests detailed explanations with examples.\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = META_PROMPT  \n",
    "\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=0.7, \n",
    "                         num_ctx=150, \n",
    "                         num_predict=150)\n",
    "\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
