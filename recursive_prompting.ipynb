{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': '\\nExplain Explain the concept of Decision Trees and their advantages. in a detailed manner.\\nThen, review your explanation and improve it by making it more structured and clear.\\nFinally, summarize your explanation in three key points.\\n', 'stream': False, 'options': {'temperature': 0.7, 'num_ctx': 300, 'num_predict': 300}}\n",
      "**Explanation of Decision Trees**\n",
      "\n",
      "A decision tree is a graphical representation of a decision-making process, where each internal node represents a feature or attribute, each branch represents a possible decision, and each leaf node represents an outcome or classification. The decision tree is constructed by recursively partitioning the data into subsets based on the values of the features or attributes.\n",
      "\n",
      "Here's how it works:\n",
      "\n",
      "1. **Root Node**: The decision starts at the root node, which represents the input feature or attribute.\n",
      "2. **Decision Nodes**: The root node splits into two or more child nodes, each representing a possible value or range of values for the feature or attribute.\n",
      "3. **Branching**: Each child node branches out further into smaller child nodes, representing different decisions based on the feature or attribute values.\n",
      "4. **Leaf Nodes**: The final branching leads to leaf nodes, which represent the predicted outcome or classification.\n",
      "\n",
      "**Advantages of Decision Trees**\n",
      "\n",
      "Decision trees have several advantages:\n",
      "\n",
      "1.  **Interpretability**: Decision trees are easy to understand and interpret, making them a popular choice for explaining complex decisions.\n",
      "2.  **Handling categorical features**: Decision trees can handle categorical features without any preprocessing.\n",
      "3.  **Handling missing values**: Most decision tree algorithms can handle missing values by either ignoring them or using a specific strategy to impute the missing values.\n",
      "4.  **Handling high-dimensional data**: While not all decision tree algorithms perform well on high-dimensional data, some like Random Forests and Gradient Boosting\n",
      "Time taken: 124.534s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## RECURSIVE PROMPTING\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "MESSAGE = \"Explain the concept of Decision Trees and their advantages.\"\n",
    "\n",
    "RECURSIVE_PROMPT = \\\n",
    "f\"\"\"\n",
    "Explain {MESSAGE} in a detailed manner.\n",
    "Then, review your explanation and improve it by making it more structured and clear.\n",
    "Finally, summarize your explanation in three key points.\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = RECURSIVE_PROMPT  \n",
    "\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=0.7, \n",
    "                         num_ctx=300, \n",
    "                         num_predict=300)\n",
    "\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
